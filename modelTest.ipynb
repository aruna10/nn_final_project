{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_folder = r\"preprocessed-boneage-training-dataset\"\n",
    "test_folder = r\"boneage-test-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of folders in the train and test directories\n",
    "num_classes_train = len(os.listdir(train_folder))\n",
    "num_classes_test = len(os.listdir(test_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Load the metadata from the CSV file\n",
    "csv_file_path = r\"boneage-training-dataset.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Lists to store the image data and bone age labels\n",
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "male      6833\n",
      "female    5778\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['gender'] = df['male'].apply(lambda x: 'male' if x else 'female')\n",
    "print(df['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('male', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1377</td>\n",
       "      <td>180</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1378</td>\n",
       "      <td>12</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1379</td>\n",
       "      <td>94</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1380</td>\n",
       "      <td>120</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1381</td>\n",
       "      <td>82</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12606</th>\n",
       "      <td>15605</td>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12607</th>\n",
       "      <td>15606</td>\n",
       "      <td>113</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>15608</td>\n",
       "      <td>55</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>15609</td>\n",
       "      <td>150</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12610</th>\n",
       "      <td>15610</td>\n",
       "      <td>132</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12611 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  boneage  gender\n",
       "0       1377      180  female\n",
       "1       1378       12  female\n",
       "2       1379       94  female\n",
       "3       1380      120    male\n",
       "4       1381       82  female\n",
       "...      ...      ...     ...\n",
       "12606  15605       50  female\n",
       "12607  15606      113  female\n",
       "12608  15608       55  female\n",
       "12609  15609      150    male\n",
       "12610  15610      132    male\n",
       "\n",
       "[12611 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.7764706  0.67058825 0.30980393 ... 0.3137255  0.3137255  0.31764707]\n",
      "  [1.         1.         0.50980395 ... 0.30980393 0.30980393 0.3137255 ]\n",
      "  [1.         1.         0.96862745 ... 0.30588236 0.30588236 0.30588236]\n",
      "  ...\n",
      "  [0.16470589 0.16470589 0.16862746 ... 0.18431373 0.18431373 0.18431373]\n",
      "  [0.16470589 0.16862746 0.16862746 ... 0.18431373 0.18431373 0.18431373]\n",
      "  [0.16470589 0.16862746 0.16862746 ... 0.18431373 0.18431373 0.18431373]]\n",
      "\n",
      " [[0.2784314  0.2784314  0.2784314  ... 0.2784314  0.2784314  0.2784314 ]\n",
      "  [0.2784314  0.2784314  0.2784314  ... 0.2784314  0.2784314  0.2784314 ]\n",
      "  [0.2784314  0.2784314  0.2784314  ... 0.2784314  0.2784314  0.2784314 ]\n",
      "  ...\n",
      "  [0.2784314  0.2784314  0.2784314  ... 0.27058825 0.27058825 0.27058825]\n",
      "  [0.2784314  0.2784314  0.2784314  ... 0.27058825 0.27450982 0.27450982]\n",
      "  [0.2784314  0.2784314  0.2784314  ... 0.27450982 0.27450982 0.27450982]]\n",
      "\n",
      " [[1.         1.         1.         ... 0.36862746 0.25490198 0.18039216]\n",
      "  [1.         1.         1.         ... 0.36862746 0.25490198 0.18039216]\n",
      "  [1.         1.         1.         ... 0.36862746 0.25490198 0.18039216]\n",
      "  ...\n",
      "  [0.65882355 0.5764706  0.52156866 ... 0.34901962 0.24313726 0.16470589]\n",
      "  [0.6431373  0.5294118  0.43137255 ... 0.35686275 0.24313726 0.16470589]\n",
      "  [0.7058824  0.5882353  0.5137255  ... 0.35686275 0.24313726 0.16862746]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.11372549 0.10980392 0.10980392 ... 0.10196079 0.10196079 0.10196079]\n",
      "  [0.10980392 0.10980392 0.10588235 ... 0.09411765 0.09803922 0.09803922]\n",
      "  [0.10980392 0.10588235 0.10588235 ... 0.09019608 0.09019608 0.09411765]\n",
      "  ...\n",
      "  [0.08627451 0.08627451 0.08235294 ... 0.03529412 0.03529412 0.03529412]\n",
      "  [0.08627451 0.08627451 0.08627451 ... 0.03529412 0.03529412 0.03529412]\n",
      "  [0.08627451 0.08627451 0.08627451 ... 0.03137255 0.03529412 0.03529412]]\n",
      "\n",
      " [[0.03137255 0.03137255 0.03137255 ... 0.03529412 0.03529412 0.03529412]\n",
      "  [0.03137255 0.03137255 0.03137255 ... 0.03529412 0.03529412 0.03529412]\n",
      "  [0.03137255 0.03137255 0.03137255 ... 0.03529412 0.03529412 0.03529412]\n",
      "  ...\n",
      "  [0.09803922 0.09803922 0.09803922 ... 0.08627451 0.08627451 0.08627451]\n",
      "  [0.09803922 0.09803922 0.09803922 ... 0.09019608 0.09019608 0.09019608]\n",
      "  [0.10196079 0.09803922 0.09803922 ... 0.09019608 0.09019608 0.09019608]]\n",
      "\n",
      " [[0.17254902 0.16470589 0.16078432 ... 0.08627451 0.08627451 0.08627451]\n",
      "  [0.18431373 0.17254902 0.16862746 ... 0.08235294 0.08627451 0.08627451]\n",
      "  [0.8392157  0.84313726 0.827451   ... 0.08235294 0.08627451 0.08627451]\n",
      "  ...\n",
      "  [0.0627451  0.0627451  0.0627451  ... 0.05490196 0.05490196 0.05490196]\n",
      "  [0.0627451  0.0627451  0.0627451  ... 0.05490196 0.05490196 0.05490196]\n",
      "  [0.0627451  0.0627451  0.0627451  ... 0.05490196 0.05490196 0.05490196]]]\n",
      "[180  12  94 ...  55 150 132]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the rows in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    image_id = row['id']\n",
    "    image_filename = f\"{image_id}.png\"  # Assuming the image filename is stored as an integer 'id'\n",
    "    bone_age = row['boneage']\n",
    "    image_path = os.path.join(train_folder, image_filename)\n",
    "    if os.path.isfile(image_path):\n",
    "        try:\n",
    "            # Open and preprocess the image\n",
    "            img = Image.open(image_path)\n",
    "            # Preprocess the image as needed (e.g., resize, normalization)\n",
    "            img = np.array(img)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            # Add the preprocessed image and bone age label to the lists\n",
    "            x_train.append(img)\n",
    "            y_train.append(bone_age)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {image_filename}, Error: {e}\")\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_train = np.array(x_train)#this has images as numbers\n",
    "y_train = np.array(y_train)#tis has bone age in number\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 363ms/step - loss: 3439.5803 - val_loss: 1810.1487\n",
      "Epoch 2/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 355ms/step - loss: 1702.0905 - val_loss: 1806.4570\n",
      "Epoch 3/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 354ms/step - loss: 1724.5748 - val_loss: 1761.6134\n",
      "Epoch 4/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 356ms/step - loss: 1684.4677 - val_loss: 2102.8213\n",
      "Epoch 5/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 354ms/step - loss: 1734.4781 - val_loss: 1719.4161\n",
      "Epoch 6/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 353ms/step - loss: 1675.5520 - val_loss: 1807.9786\n",
      "Epoch 7/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 360ms/step - loss: 1694.7572 - val_loss: 1684.1202\n",
      "Epoch 8/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 355ms/step - loss: 1670.9261 - val_loss: 1670.9980\n",
      "Epoch 9/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 354ms/step - loss: 1588.1448 - val_loss: 1659.6096\n",
      "Epoch 10/10\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 355ms/step - loss: 1597.8241 - val_loss: 1677.0642\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step\n",
      "Validation MSE: 1677.0643755795556\n",
      "Validation MAE: 33.92787254173228\n",
      "Validation R2: 0.05317421927924548\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the images to [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape the data to match the CNN input shape (assuming grayscale images)\n",
    "input_shape = x_train[0].shape + (1,)\n",
    "x_train = x_train.reshape(-1, *input_shape)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build your CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer for regression (bone age)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model with the validation data\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "# Calculate validation metrics\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print validation metrics\n",
    "print(\"Validation MSE:\", mse_val)\n",
    "print(\"Validation MAE:\", mae_val)\n",
    "print(\"Validation R2:\", r2_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 18m 41s]\n",
      "val_loss: 1731.088623046875\n",
      "\n",
      "Best val_loss So Far: 1711.6434326171875\n",
      "Total elapsed time: 01h 16m 28s\n"
     ]
    }
   ],
   "source": [
    "# Define the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='cnn_hyperparameter_tuning'\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'filters': 128, 'kernel_size': 5, 'pool_size': 3, 'units': 64, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rohit Kumar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparameters.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=best_model.optimizer, \n",
    "                   loss='mean_squared_error', \n",
    "                   metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_history = best_model.fit(x_train, y_train, \n",
    "                         validation_data=(x_val, y_val), \n",
    "                         epochs=10, \n",
    "                         batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the best model\n",
    "best_model.save('best_cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
